{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Author: Jacob Gildenblat, 2014\n",
    "#License: you may use this for whatever you like \n",
    "import sys, glob, argparse\n",
    "import numpy as np\n",
    "import math, cv2\n",
    "from scipy.stats import multivariate_normal\n",
    "import time\n",
    "from sklearn import svm\n",
    "\n",
    "def use_fisher_pooling():\n",
    "    def dictionary(descriptors, N):\n",
    "        em = cv2.EM(N)\n",
    "        em.train(descriptors)\n",
    "\n",
    "        return np.float32(em.getMat(\"means\")), \\\n",
    "            np.float32(em.getMatVector(\"covs\")), np.float32(em.getMat(\"weights\"))[0]\n",
    "\n",
    "    def image_descriptors(file):\n",
    "        img = cv2.imread(file, 0)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        _ , descriptors = cv2.SIFT().detectAndCompute(img, None)\n",
    "        return descriptors\n",
    "\n",
    "    def folder_descriptors(folder):\n",
    "        print(folder)\n",
    "        files = glob.glob(folder + \"/*.jpg\")\n",
    "        print(\"Calculating descriptos. Number of images is\", len(files))\n",
    "        return np.concatenate([image_descriptors(file) for file in files])\n",
    "\n",
    "    def likelihood_moment(x, ytk, moment):\t\n",
    "        x_moment = np.power(np.float32(x), moment) if moment > 0 else np.float32([1])\n",
    "        return x_moment * ytk\n",
    "\n",
    "    def likelihood_statistics(samples, means, covs, weights):\n",
    "        gaussians, s0, s1,s2 = {}, {}, {}, {}\n",
    "        samples = zip(range(0, len(samples)), samples)\n",
    "\n",
    "        g = [multivariate_normal(mean=means[k], cov=covs[k]) for k in range(0, len(weights)) ]\n",
    "        for index, x in samples:\n",
    "            gaussians[index] = np.array([g_k.pdf(x) for g_k in g])\n",
    "\n",
    "        for k in range(0, len(weights)):\n",
    "            s0[k], s1[k], s2[k] = 0, 0, 0\n",
    "            for index, x in samples:\n",
    "                probabilities = np.multiply(gaussians[index], weights)\n",
    "                probabilities = probabilities / np.sum(probabilities)\n",
    "                s0[k] = s0[k] + likelihood_moment(x, probabilities[k], 0)\n",
    "                s1[k] = s1[k] + likelihood_moment(x, probabilities[k], 1)\n",
    "                s2[k] = s2[k] + likelihood_moment(x, probabilities[k], 2)\n",
    "\n",
    "        return s0, s1, s2\n",
    "\n",
    "    def fisher_vector_weights(s0, s1, s2, means, covs, w, T):\n",
    "        return np.float32([((s0[k] - T * w[k]) / np.sqrt(w[k]) ) for k in range(0, len(w))])\n",
    "\n",
    "    def fisher_vector_means(s0, s1, s2, means, sigma, w, T):\n",
    "        return np.float32([(s1[k] - means[k] * s0[k]) / (np.sqrt(w[k] * sigma[k])) for k in range(0, len(w))])\n",
    "\n",
    "    def fisher_vector_sigma(s0, s1, s2, means, sigma, w, T):\n",
    "        return np.float32([(s2[k] - 2 * means[k]*s1[k]  + (means[k]*means[k] - sigma[k]) * s0[k]) / (np.sqrt(2*w[k])*sigma[k])  for k in range(0, len(w))])\n",
    "\n",
    "    def normalize(fisher_vector):\n",
    "        v = np.sqrt(abs(fisher_vector)) * np.sign(fisher_vector)\n",
    "        return v / np.sqrt(np.dot(v, v))\n",
    "\n",
    "    def fisher_vector(samples, means, covs, w):\n",
    "        s0, s1, s2 =  likelihood_statistics(samples, means, covs, w)\n",
    "        T = samples.shape[0]\n",
    "        covs = np.float32([np.diagonal(covs[k]) for k in range(0, covs.shape[0])])\n",
    "        a = fisher_vector_weights(s0, s1, s2, means, covs, w, T)\n",
    "        b = fisher_vector_means(s0, s1, s2, means, covs, w, T)\n",
    "        c = fisher_vector_sigma(s0, s1, s2, means, covs, w, T)\n",
    "        fv = np.concatenate([np.concatenate(a), np.concatenate(b), np.concatenate(c)])\n",
    "        fv = normalize(fv)\n",
    "        return fv\n",
    "\n",
    "    def generate_gmm(input_folder, N):\n",
    "        print (input_folder + '/*')\n",
    "        words = np.concatenate([folder_descriptors(folder) for folder in glob.glob(input_folder + '/*')]) \n",
    "        print(\"Training GMM of size\", N)\n",
    "        means, covs, weights = dictionary(words, N)\n",
    "        #Throw away gaussians with weights that are too small:\n",
    "        th = 1.0 / N\n",
    "        means = np.float32([m for k,m in zip(range(0, len(weights)), means) if weights[k] > th])\n",
    "        covs = np.float32([m for k,m in zip(range(0, len(weights)), covs) if weights[k] > th])\n",
    "        weights = np.float32([m for k,m in zip(range(0, len(weights)), weights) if weights[k] > th])\n",
    "\n",
    "        np.save(\"means.gmm\", means)\n",
    "        np.save(\"covs.gmm\", covs)\n",
    "        np.save(\"weights.gmm\", weights)\n",
    "        return means, covs, weights\n",
    "\n",
    "    def get_fisher_vectors_from_folder(folder, gmm):\n",
    "        files = glob.glob(folder + \"/*.jpg\")\n",
    "        return np.float32([fisher_vector(image_descriptors(file), *gmm) for file in files])\n",
    "\n",
    "    def fisher_features(folder, gmm):\n",
    "        folders = glob.glob(folder + \"/*\")\n",
    "        features = {f : get_fisher_vectors_from_folder(f, gmm) for f in folders}\n",
    "        return features\n",
    "\n",
    "    def train(gmm, features):\n",
    "        X = np.concatenate(features.values())\n",
    "        Y = np.concatenate([np.float32([i]*len(v)) for i,v in zip(range(0, len(features)), features.values())])\n",
    "\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(X, Y)\n",
    "        return clf\n",
    "\n",
    "    def success_rate(classifier, features):\n",
    "        print(\"Applying the classifier...\")\n",
    "        X = np.concatenate(np.array(features.values()))\n",
    "        Y = np.concatenate([np.float32([i]*len(v)) for i,v in zip(range(0, len(features)), features.values())])\n",
    "        res = float(sum([a==b for a,b in zip(classifier.predict(X), Y)])) / len(Y)\n",
    "        return res\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"Classification\"\"\"\n",
    "    def generate_prec_rec_curve(y_true, y_pred_prob):\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "\n",
    "        for threshold in np.arange(0,1, 0.001):\n",
    "            y_thresholded_pred = (y_pred_prob > threshold) * 1.0\n",
    "            tp = tn = fp = fn = 0\n",
    "\n",
    "            for i in range(len(y_true)):\n",
    "                if y_true[i] == 0:\n",
    "                    if y_thresholded_pred[i] == 0:\n",
    "                        tn += 1\n",
    "                    else:\n",
    "                        fp += 1\n",
    "                else:\n",
    "                    if y_thresholded_pred[i] == 1:\n",
    "                        tp += 1\n",
    "                    else:\n",
    "                        fn += 1\n",
    "\n",
    "            if tp + fp == 0:\n",
    "                break\n",
    "    #             precisions.append(0.0)\n",
    "            else:\n",
    "                precisions.append(tp / float(tp + fp))\n",
    "            if tp + fn == 0:\n",
    "                break\n",
    "    #             recalls.append(0.0)\n",
    "            else:\n",
    "                recalls.append(tp / float(tp + fn))\n",
    "\n",
    "        return precisions, recalls\n",
    "\n",
    "    def display_all_class_pr_curves(test_y_ohe, score_y):\n",
    "        for i in range(test_y_ohe.shape[1]):\n",
    "            pr_curve = generate_prec_rec_curve(test_y_ohe[:, i], score_y[:, i])\n",
    "            plt.plot(pr_curve[1], pr_curve[0])\n",
    "        plt.xlabel(\"recall\")\n",
    "        plt.ylabel(\"precision\")\n",
    "        plt.ylim(0, 1.1)\n",
    "    \n",
    "    def one_hot_encoding(passed_y, n_classes):\n",
    "        final_labels = []\n",
    "\n",
    "        for y in passed_y:\n",
    "            encoded_array = np.zeros(n_classes)\n",
    "            encoded_array[y - 1] = 1\n",
    "            final_labels.append(encoded_array)\n",
    "\n",
    "        return np.asarray(final_labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def classification_accuracy(classifier_str, train_x, train_y, test_x, test_y):\n",
    "        #  reduce to proper dimensions for classifier\n",
    "        train_x = train_x.squeeze()\n",
    "        train_y = train_y.squeeze()\n",
    "        test_x = test_x.squeeze()\n",
    "        test_y = test_y.squeeze()\n",
    "#         test_y_ohe = self.one_hot_encoding(test_y, 10)\n",
    "        test_y_ohe = one_hot_encoding(test_y, 2)\n",
    "\n",
    "\n",
    "        self.rf_clf = RandomForestClassifier(n_estimators=10000)\n",
    "        self.rf_clf.fit(train_x, train_y)\n",
    "\n",
    "        score_y = self.rf_clf.predict_proba(test_x)\n",
    "        self.display_all_class_pr_curves(test_y_ohe, score_y)\n",
    "\n",
    "        return self.rf_clf.score(test_x, test_y)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def load_gmm(folder = \"\"):\n",
    "        files = [\"means.gmm.npy\", \"covs.gmm.npy\", \"weights.gmm.npy\"]\n",
    "        return map(lambda file: load(file), map(lambda s : folder + \"/\" , files))\n",
    "\n",
    "    # def get_args():\n",
    "    #     parser = argparse.ArgumentParser()\n",
    "    #     parser.add_argument('-d' , \"--dir\", help=\"Directory with images\" , default='.')\n",
    "    #     parser.add_argument(\"-g\" , \"--loadgmm\" , help=\"Load Gmm dictionary\", action = 'store_true', default = False)\n",
    "    #     parser.add_argument('-n' , \"--number\", help=\"Number of words in dictionary\" , default=5, type=int)\n",
    "    #     args = parser.parse_args()\n",
    "    #     return args\n",
    "\n",
    "    # args = get_args()\n",
    "    \n",
    "    \n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    \n",
    "    working_folder = \"/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images\"\n",
    "    working_folder_test = \"/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images_test\"\n",
    "\n",
    "    \n",
    "    gmm = load_gmm(working_folder) if False else generate_gmm(working_folder, 5)\n",
    "    fisher_features = fisher_features(working_folder, gmm)\n",
    "#     fisher_features_test = fisher_features(working_folder_test, gmm)\n",
    "\n",
    "    #TBD, split the features into training and validation\n",
    "    classifier = train(gmm, fisher_features)\n",
    "    rate = success_rate(classifier, fisher_features)\n",
    "    print(\"Success rate is\", rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/*\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/8\n",
      "('Calculating descriptos. Number of images is', 28)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/5\n",
      "('Calculating descriptos. Number of images is', 44)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/9\n",
      "('Calculating descriptos. Number of images is', 45)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/2\n",
      "('Calculating descriptos. Number of images is', 47)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/1\n",
      "('Calculating descriptos. Number of images is', 41)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/6\n",
      "('Calculating descriptos. Number of images is', 50)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/3\n",
      "('Calculating descriptos. Number of images is', 31)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/4\n",
      "('Calculating descriptos. Number of images is', 45)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/7\n",
      "('Calculating descriptos. Number of images is', 45)\n",
      "/home/tuna/Projects/CS601R/Project1/lib/leedsbutterfly/fisher_images/images/10\n",
      "('Calculating descriptos. Number of images is', 42)\n",
      "('Training GMM of size', 5)\n",
      "Applying the classifier...\n",
      "('Success rate is', 0.11961722488038277)\n"
     ]
    }
   ],
   "source": [
    "use_fisher_pooling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
